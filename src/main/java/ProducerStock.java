import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.net.HttpURLConnection;
import java.net.MalformedURLException;
import java.net.URL;
import java.util.Properties;

import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/*
 * This Java source file was generated by the Gradle 'init' task.
 */
public class ProducerStock {

    // https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE
    // &from_currency=BTC&to_currency=USD&apikey=6C9FT77IAHQBM906

    // https://justpaste.it/6sy1x

    public static void main(String[] args) throws IOException, InterruptedException {
        Logger logger = LoggerFactory.getLogger(ProducerStock.class);

        // Crear las propiedades del producer
        Properties properties = new Properties();
        properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");

        properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        // vamos a hacer un producer más seguro
        

        // el acks all nos 'garantiza' que se ha escrito
        // el mensaje en varias réplicas (min.insync.replicas)
        properties.setProperty(ProducerConfig.ACKS_CONFIG, "all");

        // El número máximo de reintentos
        properties.setProperty(ProducerConfig.RETRIES_CONFIG,
             String.valueOf(Integer.MAX_VALUE));

        // Activar la idempotencia a nivel de productor
        properties.setProperty(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, 
            "true");
    
            // El más seguro, pero penaliza el rendimiento
        properties.setProperty(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION
        , "5");
        

        // Crearemos el producer

        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<String, String>(properties);

        // Enviaremos los datos

        for (int i = 0; i < 10; i++) {
            URL url = new URL(
            "https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency=BTC&to_currency=USD&apikey=6C9FT77IAHQBM906"
                );

            HttpURLConnection conn =
                (HttpURLConnection) url.openConnection();
            
                conn.setRequestMethod("GET");
                conn.setRequestProperty("Accept", "application/json");
            
            if (conn.getResponseCode() != 200) {
                logger.error("No ha conectado correctamente");
            }

            BufferedReader br = 
                new BufferedReader(
                    new InputStreamReader(
                        conn.getInputStream()
                    )
                );
            
            String output;
            String completo = "";

            logger.info("Recibido del servidor:");

            while ((output = br.readLine()) != null) {
                logger.info(output);
                completo += output;
            }

            conn.disconnect();
            
            // Crear los datos
            ProducerRecord<String, String> producerRecord = 
                new ProducerRecord<String, String>("btn",
                completo);

            // Enviarlos
            kafkaProducer.send(producerRecord, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    // Se ejecuta cuando se ha terminado de enviar
                    // o bien ha habido un error en el envío
                    if (exception == null) {
                        // todo ha ido bien
                        logger.info("mensaje enviado");
                        logger.info("topic " + metadata.topic());
                        logger.info("offset " + metadata.offset());
                        logger.info("particion "+metadata.partition());
                    } else {
                        // no ha ido bien
                        logger.error(exception.getLocalizedMessage(), exception);
                    }

                }
            });

            kafkaProducer.flush();
            Thread.sleep(15000);
        }


        // Cerrar
        kafkaProducer.close();

    }
}
